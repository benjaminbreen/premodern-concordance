{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune BGE-M3 for Premodern Concordance (v3)\n",
    "\n",
    "This notebook fine-tunes the BGE-M3 multilingual embedding model on 889 curated\n",
    "cross-lingual entity matching pairs + 154 hard negatives.\n",
    "\n",
    "**How to use:**\n",
    "1. Make sure GPU is enabled: Runtime → Change runtime type → T4 GPU\n",
    "2. Run each cell in order (Shift+Enter or click the play button)\n",
    "3. Cell 2 will ask you to upload a file — upload `curated_training_pairs.json`\n",
    "4. Training takes ~10-20 minutes\n",
    "5. The last cell downloads the fine-tuned model as a zip file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 1: Install dependencies ──────────────────────────────────────────────\n",
    "# This installs the libraries needed for fine-tuning. Takes ~1-2 minutes.\n",
    "\n",
    "!pip install -q sentence-transformers torch\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime → Change runtime type → T4 GPU\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 2: Upload training data ──────────────────────────────────────────────\n",
    "# Click 'Choose Files' and select: data/curated_training_pairs.json\n",
    "\n",
    "from google.colab import files\n",
    "import json\n",
    "\n",
    "print(\"Please upload curated_training_pairs.json when prompted...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load and verify\n",
    "filename = list(uploaded.keys())[0]\n",
    "with open(filename) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"\\nLoaded: {filename}\")\n",
    "print(f\"Batches: {len(data['batches'])}\")\n",
    "total_pos = sum(len(b['positive_pairs']) for b in data['batches'])\n",
    "total_neg = sum(len(b['hard_negatives']) for b in data['batches'])\n",
    "print(f\"Total: {total_pos} positive pairs, {total_neg} hard negatives\")\n",
    "for b in data['batches']:\n",
    "    print(f\"  {b['batch_id']}: {len(b['positive_pairs'])} pos, {len(b['hard_negatives'])} neg\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 3: Load base model ───────────────────────────────────────────────────\n",
    "# Downloads BGE-M3 from Hugging Face (~2.2 GB). Takes ~2-5 minutes.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Downloading BGE-M3 base model from Hugging Face...\")\n",
    "print(\"(This is ~2.2 GB, may take a few minutes)\")\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "print(f\"Model loaded! Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 4: Prepare training data ─────────────────────────────────────────────\n",
    "\n",
    "import random\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "# Flatten batches with deduplication\n",
    "all_positives = []\n",
    "all_negatives = []\n",
    "seen_pos = set()\n",
    "seen_neg = set()\n",
    "\n",
    "for batch in data['batches']:\n",
    "    for p in batch['positive_pairs']:\n",
    "        key = (p['source'].lower().strip(), p['target'].lower().strip())\n",
    "        rkey = (key[1], key[0])\n",
    "        if key not in seen_pos and rkey not in seen_pos:\n",
    "            seen_pos.add(key)\n",
    "            all_positives.append(p)\n",
    "    for n in batch['hard_negatives']:\n",
    "        key = (n['source'].lower().strip(), n['target'].lower().strip())\n",
    "        if key not in seen_neg:\n",
    "            seen_neg.add(key)\n",
    "            all_negatives.append(n)\n",
    "\n",
    "print(f\"Unique positives: {len(all_positives)}\")\n",
    "print(f\"Unique negatives: {len(all_negatives)}\")\n",
    "\n",
    "# Create training examples (both directions for each positive pair)\n",
    "examples = []\n",
    "for pair in all_positives:\n",
    "    examples.append(InputExample(texts=[pair['source'], pair['target']]))\n",
    "    examples.append(InputExample(texts=[pair['target'], pair['source']]))\n",
    "\n",
    "random.shuffle(examples)\n",
    "print(f\"Training examples: {len(examples)} (each pair in both directions)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 5: Baseline evaluation (BEFORE training) ─────────────────────────────\n",
    "# See how the base model performs on our pairs before we fine-tune it.\n",
    "\n",
    "def evaluate(model, positives, negatives, label=\"\"):\n",
    "    \"\"\"Evaluate model on sample of positives and negatives.\"\"\"\n",
    "    eval_pos = random.sample(positives, min(80, len(positives)))\n",
    "    eval_neg = negatives[:80]\n",
    "\n",
    "    pos_sims = []\n",
    "    for p in eval_pos:\n",
    "        e1 = model.encode(p['source'], normalize_embeddings=True)\n",
    "        e2 = model.encode(p['target'], normalize_embeddings=True)\n",
    "        pos_sims.append(float(e1 @ e2))\n",
    "\n",
    "    neg_sims = []\n",
    "    for n in eval_neg:\n",
    "        e1 = model.encode(n['source'], normalize_embeddings=True)\n",
    "        e2 = model.encode(n['target'], normalize_embeddings=True)\n",
    "        neg_sims.append(float(e1 @ e2))\n",
    "\n",
    "    avg_pos = sum(pos_sims) / len(pos_sims)\n",
    "    avg_neg = sum(neg_sims) / len(neg_sims)\n",
    "    sep = avg_pos - avg_neg\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{label}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  Avg positive similarity: {avg_pos:.4f} (n={len(pos_sims)})\")\n",
    "    print(f\"  Avg negative similarity: {avg_neg:.4f} (n={len(neg_sims)})\")\n",
    "    print(f\"  Separation:              {sep:.4f}\")\n",
    "\n",
    "    # Spot checks\n",
    "    checks = [\n",
    "        ('canela', 'cinnamon', True),\n",
    "        ('febre', 'fever', True),\n",
    "        ('mesmerism', 'hypnosis', True),\n",
    "        ('Falling sickness', 'epilepsy', True),\n",
    "        ('vibratiuncles', 'memory traces', True),\n",
    "        ('unbewusster Schluss', 'unconscious inference', True),\n",
    "        ('désagrégation', 'dissociation', True),\n",
    "        ('Galeno', 'Avicenna', False),\n",
    "        ('canfora', 'canela', False),\n",
    "        ('phrenology', 'phenology', False),\n",
    "        ('caloric', 'calorie', False),\n",
    "        ('hystérie', 'hystérèse', False),\n",
    "    ]\n",
    "    print(f\"\\n  Spot checks:\")\n",
    "    for src, tgt, should_match in checks:\n",
    "        e1 = model.encode(src, normalize_embeddings=True)\n",
    "        e2 = model.encode(tgt, normalize_embeddings=True)\n",
    "        sim = float(e1 @ e2)\n",
    "        ok = (sim > 0.5) == should_match\n",
    "        mark = 'GOOD' if ok else 'WARN'\n",
    "        expect = 'match' if should_match else 'no match'\n",
    "        print(f\"    [{mark}] {src:30} ↔ {tgt:25} {sim:.3f}  ({expect})\")\n",
    "\n",
    "    return avg_pos, avg_neg, sep\n",
    "\n",
    "baseline = evaluate(model, all_positives, all_negatives, \"BASELINE (before training)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 6: Fine-tune! ────────────────────────────────────────────────────────\n",
    "# This is the main training step. ~10-20 minutes on a T4 GPU.\n",
    "\n",
    "from sentence_transformers import losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "WARMUP_STEPS = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "OUTPUT_DIR = \"finetuned-bge-m3-v3\"\n",
    "\n",
    "train_dataloader = DataLoader(examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "print(f\"Training config:\")\n",
    "print(f\"  Examples:     {len(examples)}\")\n",
    "print(f\"  Batch size:   {BATCH_SIZE}\")\n",
    "print(f\"  Epochs:       {EPOCHS}\")\n",
    "print(f\"  Steps/epoch:  {len(train_dataloader)}\")\n",
    "print(f\"  Total steps:  {total_steps}\")\n",
    "print(f\"  Warmup:       {WARMUP_STEPS}\")\n",
    "print(f\"  LR:           {LEARNING_RATE}\")\n",
    "print(f\"  Loss:         MultipleNegativesRankingLoss\")\n",
    "print(f\"\\nStarting training...\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    output_path=OUTPUT_DIR,\n",
    "    show_progress_bar=True,\n",
    "    save_best_model=True,\n",
    "    optimizer_params={\"lr\": LEARNING_RATE},\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining complete! Model saved to {OUTPUT_DIR}/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 7: Post-training evaluation ──────────────────────────────────────────\n",
    "# Load the saved model and compare to baseline.\n",
    "\n",
    "model_v3 = SentenceTransformer(\"finetuned-bge-m3-v3\")\n",
    "result = evaluate(model_v3, all_positives, all_negatives, \"POST-TRAINING (after fine-tuning)\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"IMPROVEMENT SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Positive avg: {baseline[0]:.4f} → {result[0]:.4f} (Δ {result[0]-baseline[0]:+.4f})\")\n",
    "print(f\"  Negative avg: {baseline[1]:.4f} → {result[1]:.4f} (Δ {result[1]-baseline[1]:+.4f})\")\n",
    "print(f\"  Separation:   {baseline[2]:.4f} → {result[2]:.4f} (Δ {result[2]-baseline[2]:+.4f})\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Cell 8: Download the fine-tuned model ─────────────────────────────────────\n",
    "# Zips the model (~2.2 GB) and triggers a browser download.\n",
    "# If the download doesn't start, look for the file in the left sidebar\n",
    "# (folder icon) and right-click → Download.\n",
    "\n",
    "import shutil\n",
    "\n",
    "print(\"Zipping model... (this takes a minute)\")\n",
    "shutil.make_archive(\"finetuned-bge-m3-v3\", \"zip\", \".\", \"finetuned-bge-m3-v3\")\n",
    "print(\"Done! Starting download...\")\n",
    "\n",
    "files.download(\"finetuned-bge-m3-v3.zip\")\n",
    "print(\"\\nAfter downloading, unzip into your project:\")\n",
    "print(\"  unzip finetuned-bge-m3-v3.zip -d /path/to/Premodern\\\\ Concordance/models/\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}