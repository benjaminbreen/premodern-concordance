{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune BGE-M3 for Premodern Cross-Lingual Entity Matching\n",
    "\n",
    "This notebook fine-tunes the BGE-M3 multilingual embedding model on training pairs from early modern texts.\n",
    "\n",
    "**Runtime**: Go to Runtime > Change runtime type > Select T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q sentence-transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training_pairs.json\n",
    "from google.colab import files\n",
    "print(\"Upload training_pairs.json:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load training data\n",
    "with open('training_pairs.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Categories: {list(data['categories'].keys())}\")\n",
    "total_pos = sum(len(pairs['positive_pairs']) for pairs in data['categories'].values())\n",
    "total_neg = sum(len(pairs['hard_negatives']) for pairs in data['categories'].values())\n",
    "print(f\"Total positive pairs: {total_pos}\")\n",
    "print(f\"Total hard negatives: {total_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(data: dict) -> list:\n",
    "    \"\"\"Create positive pairs for MultipleNegativesRankingLoss.\"\"\"\n",
    "    examples = []\n",
    "    for category, pairs in data['categories'].items():\n",
    "        positives = pairs['positive_pairs']\n",
    "        for pair in positives:\n",
    "            # Positive pair both directions\n",
    "            examples.append(InputExample(texts=[pair['source'], pair['target']]))\n",
    "            examples.append(InputExample(texts=[pair['target'], pair['source']]))\n",
    "    return examples\n",
    "\n",
    "examples = create_pairs(data)\n",
    "random.shuffle(examples)\n",
    "print(f\"Created {len(examples)} training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model (fresh, not from previous fine-tune)\n",
    "print(\"Loading base BGE-M3 model...\")\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "WARMUP_STEPS = 100\n",
    "OUTPUT_DIR = 'finetuned-bge-m3-v2'\n",
    "\n",
    "# Create data loader\n",
    "train_dataloader = DataLoader(examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Use MultipleNegativesRankingLoss - works well with pairs\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Warmup steps: {WARMUP_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "print(\"Starting training...\")\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    output_path=OUTPUT_DIR,\n",
    "    show_progress_bar=True,\n",
    "    save_best_model=True,\n",
    ")\n",
    "print(f\"Training complete! Model saved to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation\n",
    "print(\"\\n--- Evaluation on test pairs ---\")\n",
    "model = SentenceTransformer(OUTPUT_DIR)\n",
    "\n",
    "test_pairs = [\n",
    "    # Should be similar (cross-lingual same referent)\n",
    "    (\"Galeno\", \"Galen\", \"similar\"),\n",
    "    (\"Medicina\", \"Medicine\", \"similar\"),\n",
    "    (\"água\", \"water\", \"similar\"),\n",
    "    (\"febre\", \"fever\", \"similar\"),\n",
    "    (\"Lisboa\", \"Lisbon\", \"similar\"),\n",
    "    (\"sangue\", \"blood\", \"similar\"),\n",
    "    (\"Diofcorides\", \"Dioscorides\", \"similar\"),\n",
    "    (\"alambique\", \"alembic\", \"similar\"),\n",
    "    # Should be dissimilar (different referents)\n",
    "    (\"Galeno\", \"Avicenna\", \"dissimilar\"),\n",
    "    (\"água\", \"wine\", \"dissimilar\"),\n",
    "    (\"Lisboa\", \"Paris\", \"dissimilar\"),\n",
    "    (\"febre\", \"plague\", \"dissimilar\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Source':<20} {'Target':<20} {'Similarity':>10} {'Expected':>12}\")\n",
    "print(\"-\" * 65)\n",
    "for source, target, expected in test_pairs:\n",
    "    emb1 = model.encode(source, normalize_embeddings=True)\n",
    "    emb2 = model.encode(target, normalize_embeddings=True)\n",
    "    sim = float(emb1 @ emb2)\n",
    "    status = \"OK\" if (expected == \"similar\" and sim > 0.7) or (expected == \"dissimilar\" and sim < 0.7) else \"CHECK\"\n",
    "    print(f\"{source:<20} {target:<20} {sim:>10.3f} {expected:>12} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and download the model\n",
    "import shutil\n",
    "shutil.make_archive('finetuned-bge-m3-v2', 'zip', OUTPUT_DIR)\n",
    "files.download('finetuned-bge-m3-v2.zip')\n",
    "print(\"Download complete! Unzip to models/finetuned-bge-m3-v2 in your project.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
